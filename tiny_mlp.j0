
(*

  [nn ((x, y), (wxu, wyu))] returns the output [u] of the Multi-Layer Perceptron
  with inputs (x, y) and weights (wxu, wyu). [wxu] is the weight from [x] to
  [u] and [wyu] is the weigth from [y] to [u]. We suggest you use the sigmoid
  as activation function :

					   1
				 x ↦ ————————————–——
				       1 + e^{-x}

*)
let sigmoid (x) = 
	inv ( 1 + exp (-x))

let nn (p)
=
   let (x) = fst (fst p) in
	 let (y) = snd (fst p) in
	 let (wxu) = fst (snd p) in
	 let (wxy) = snd (snd p) in
	 sigmoid (x * wxu + y * wxy)

(*

   For a given input, the [error] function evaluates the distance
   between the neural network output and the expected output.

*)
let error (p)
=
  let (xu) = snd p in
  let (u) = nn (fst p) in
  let (d) = -u + xu in
  0.5 * d * d

